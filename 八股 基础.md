## 1. 服务端口号

21端口：FTP 文件传输服务
22端口：SSH 远程连接服务
53端口：DNS 域名解析服务
80端口：HTTP 超文本传输服务
443端口：HTTPS 加密的超文本传输服务
3306端口：MYSQL数据库端口
6379端口：Redis数据库端口
9200端口：Elasticsearch服务器端口
9876端口：rocketmq服务器端口



---



## 2. go 底层实现

### 2.1 map实现

> map**不是并发安全**的，解决方案：读写锁；分片锁；sync.Map(读多写少)

Go map 底层实现方式是 **Hash 表**。Go map 的数据被置入一个由桶组成的有序数组中，每个桶最多可以存放 8 个 key/value 对。**key 的 Hash 值低位用于在该数组中定位到桶，而高 8 位则用于在桶中区分 key/value 对。**

Go map 的 hash 表中的基本单位是桶，每个桶最多存 8 个键值对，超了则会链接到额外的溢出桶。所以 Go map 基本数据结构是**hash数组+桶内的key-value数组+溢出的桶链表**。

<img src="./assets/rafej6fyu0.png" alt="https://img2018.cnblogs.com/blog/1480383/201911/1480383-20191104215659319-1712154558.jpg" style="zoom: 50%;" />

当 Hash 表超过阈值需要扩容增长时，会分配一个新的桶数组，新数组的大小一般是旧数组的 2 倍。这里从旧数组将数据迁移到新数组，不会一次全量拷贝，因为耗时太大，Go 会在每次读写 Map 时以桶为单位做动态搬迁。



### 2.2 sync锁

```go
type Mutex struct {
    state int32
    sema  uint32
}
```

state存储的是互斥锁的状态，加锁和解锁，都是通过**atomic包提供的函数原子性**，操作该字段。sema用作一个信号量，主要用于等待队列。

Mutex有两种模式，在正常模式下，一个尝试加锁的goroutine会先自旋四次，自旋锁(如果不成功就一直尝试)，尝试通过原子操作获得锁，若**几次自旋之后仍不能获得锁，则通过信号量排队等待**。

当一个goroutine本次**加锁等待时间超过了1ms**后，它会把当前Mutex从正常模式切换至**“饥饿模式”**。在饥饿模式下，**Mutex的所有权直接传递给等待队列头部的goroutine**，后来者不会自旋，也不会尝试获得锁，



### 2.3 channel

<img src="./assets/00641051340b7fad47f524189574ad37.png" alt="img" style="zoom: 67%;" />

1. Channel本质上是由**三个FIFO（First In FirstOut，先进先出）队列**组成的用于**协程之间传输数据**的**协程安全**的通道；FIFO的设计是为了保障公平，让事情变得简单，原则是让等待时间最长的协程最有资格先从channel发送或接收数据；
2. 三个FIFO队列依次是**buf循环队列，sendq待发送者队列，recvq待接收者队列**。buf循环队列是大小固定的用来存放channel接收的数据的队列；**sendq待发送者队列**，用来存放等待发送数据到channel的goroutine的双向链表，**recvq待接收者队列**，用来存放等待从channel读取数据的goroutine的双向链表；sendq和recvq**可以认为不限大小**；
3. 跟函数调用传参本质都是传值一样，channel传递数据的本质就是值拷贝，引用类型数据的传递也是地址拷贝；有从缓冲区buf地址拷贝数据到接收者receiver栈内存地址，也有从发送者sender栈内存地址拷贝数据到缓冲区buf；
4. Channel里面参数的修改不是并发安全的，包括对三个队列及其他参数的访问，因此需要加锁，本质上，channel就是一个有锁队列；
5. Channel 的性能跟 sync.Mutex 差不多，没有谁比谁强。Go官方之所以推荐使用Channel进行并发协程的数据交互，是因为channel的设计理念能让程序变得简单，在大型程序、高并发复杂的运行状况中也是如此。



### 2.4 slice

切片是基于数组类型做的一层封装。它非常灵活，支持自动扩容。

<img src="./assets/v2-bb9b216149c4d53c363dc3194d6a02ca_720w.webp" alt="img" style="zoom: 80%;" />

在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容：

1. **如果期望容量大于当前容量的两倍就会使用期望容量；**
2. 如果当前切片的长度**小于阈值**（默认 256）就会将容量**翻倍**；
3. 如果当前切片的长度**大于等于阈值**（默认 256），**扩容1.25倍+192**，直到新容量大于期望容量；

```go
	if cap > doublecap {
        newcap = cap
    } else {
        const threshold = 256
        if old.cap < threshold {
            newcap = doublecap
        } else {
            // Check 0 < newcap to detect overflow
            // and prevent an infinite loop.
            for 0 < newcap && newcap < cap {
                // Transition from growing 2x for small slices
                // to growing 1.25x for large slices. This formula
                // gives a smooth-ish transition between the two.
                newcap += (newcap + 3*threshold) / 4
            }
            // Set newcap to the requested cap when
            // the newcap calculation overflowed.
            if newcap <= 0 {
                newcap = cap
            }
        }
    }
```

当数组作为函数参数时，函数操作的是数组的一个副本，不会影响原始数组；当切片作为函数参数时，函数操作的是切片的引用，会影响原始切片。



## 3. go gc

> **优化内存分配**： 对大对象的分配保持谨慎，减少大块内存的频繁分配和释放，避免内存碎片化。
>
> **调优 GC 参数**： 可以通过调整 `GOGC` 环境变量（控制垃圾回收的触发频率）等方式，根据应用的特定需求对 GC 进行调优，降低停顿时间或减少内存占用。

**追踪式 GC：从根对象（全局变量、执行栈，堆内存指针）出发**，根据对象之间的引用信息，一步步推进直到扫描完毕**整个堆**并确定需要保留的对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。
**STW**：全称是stop the word，GC期间某个阶段会停止所有的赋值器，中断你的程序逻辑，以确定引用关系。
观察GC：设置**`GODEBUG=gctrace=1`**环境变量；**pprof**包查看CPU使用、内存分配以及协程的使用情况

**三色标记法**：（解决STW问题）

白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。
灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。
黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。

**当垃圾回收开始时，只有白色对象**。随着标记过程开始进行时，**灰色对象开始出现**（着色），这时候波面便开始扩大。当一个对象的所有子节点均完成扫描时，会被着色为**黑色**。当整个堆遍历完成时，**只剩下黑色和白色对象**，这时的黑色对象为可达对象，即存活；而白色对象为不可达对象，即死亡。这个过程`可以视为以灰色对象为波面，将黑色对象和白色对象分离，使波面不断向前推进，直到所有可达的灰色对象都变为黑色对象为止的过程。

![三色标记法全貌](./assets/1713437200557RzlMu0.png)

在三色标记法的过程中对象丢失，需要同时满足下面两个条件：

条件一：白色对象被黑色对象引用
条件二：灰色对象与白色对象之间的可达关系遭到破坏

- **插入写屏障**

  规则：**当一个对象引用另外一个对象时，将另外一个对象标记为灰色**

  满足：强三色不变式。不会存在黑色对象引用白色对象

这里需要注意一点，**插入屏障仅会在堆内存中生效，不对栈内存空间生效**，这是因为go在并发运行时，大部分的操作都发生在栈上，函数调用会非常频繁。数十万goroutine的栈都进行屏障保护自然会有性能问题。

插入写屏障最大的弊端就是，在一次正常的三色标记流程结束后，**需要对栈上重新进行一次stw，然后再rescan一次**。

- **删除写屏障**

  规则：**在删除引用时，如果被删除引用的对象自身为灰色或者白色，那么被标记为灰色。**

  满足：弱三色不变式。灰色对象到白色对象的路径不会断。

弊端：一个对象的引用被删除后，即使没有其他存活的对象引用它，它**仍然会活到下一轮**。

- **混合写屏障机制**

  GC刚开始的时候，会将栈上的可达对象全部标记为黑色。

  **GC期间，任何在栈上新创建的对象，均为黑色**。（避免了二次扫描）

  > 屏障限制只在堆内存中生效。避免了最后节点对栈进行STW的问题，提升了GC效率 

  **堆上被删除的对象标记为灰色**

  **堆上新添加的对象标记为灰色**



## 4. 内存逃逸原理 举例

内存逃逸（Memory Escape）是指变量的内存分配位置从栈上转移到堆上。

通过逃逸分析，可以尽量把那些不需要分配到堆上的变量直接分配到栈上，堆上的变量变少了，会减轻堆内存分配的开销，同时也会减少垃圾回收（Garbage Collction，GC）的压力，提高程序运行速度。

- 如果变量在函数外部没有被引用，则优先放到栈上。
- 如果变量在函数外部存在引用，则必定放在堆上。

```go
func  foo() *int {
    t := 3
    return  &t
}

func  main() {
    x :=  foo()
    fmt.Println(*x)
}
// foo 函数里的变量 t 逃逸了，和预想的一致，不解的是为什么 main 函数里的 x 也逃逸了？这是因为有些函数的参数为 interface 类型，比如 fmt.Println(a ...interface{}) ，编译期间很难确定其参数的具体类型，也会发生逃逸。
```

- **减少指针使用**：尽量避免返回指向局部变量的指针。
- **限制变量作用域**：避免将其暴露给外部。
- **合理使用闭包**：尽量减少闭包捕获的局部变量数量。



## 5. 值传递

- Go里面没有`引用传递`，Go语言是`值传递`。
- 如果需要函数内部的修改能影响到函数外部，那么就传指针。
- `map/channel` 本身就是指针，是引用类型，所以直接传 `map和channel` 本身就可以。
- slice` 的赋值操作其实是针对 `slice` 结构体内部的指针进行操作，也是指针，可以直接传 `slice` 本身。` 
- `slice` 的 `append 操作` 同时需要修改结构体的 `len/cap`，类似于 `struct`，如果需要传递到函数外部，需要传指针。（或者使用函数返回值）



## 6. Goroutine | 协程

- **轻量级**：Goroutine 的栈空间初始大小只有 2KB，可以动态扩容，最大可达 1GB
- **快速启动**：Goroutine 的启动时间只有 1~2us
- **高效调度**：Goroutine 的调度器采用 M:N 模型，可以将 M 个 Goroutine 映射到 N 个 OS 线程上，实现高效调度
- **通信简单**：Goroutine 之间通过 Channel 进行通信，实现数据共享
- **无锁**：Goroutine 之间通过 Channel 进行通信，无需加锁
- **高并发**：Goroutine 可以轻松创建数十万个，实现高并发
- **高性能**：Goroutine 的调度器采用抢占式调度，实现高性能



**进程、线程与协程的区别？**

进程是操作系统分配资源和调度的基本单位，它拥有自己的独立内存空间和系统资源。每个进程都有独立的堆和栈。

线程是进程中的一个执行单元，线程共享进程的资源（如内存、文件描述符），但有独立的栈和寄存器。

协程是比线程更轻量级的并发单位，协程由程序员手动调度而非操作系统调度。**内核线程依然叫 “线程 (thread)”，用户线程叫 “协程 (co-routine)”。**

线程由 CPU 调度是抢占式的，**协程由用户态调度是协作式的，一个协程让出 CPU 后，才执行下一个协程**。



## 7. GMP 调度器

在 Go 中，**线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上**。

- **全局队列**：存放所有正在等待运行的 `G`
- **本地队列**：每个 `P` 都有一个本地队列， 用于存放当前 `P` 等待和正在运行的 `G`，每个 `P` 的本地队列中最多存放 `256` 个 `G` 。创建 `G` 时，会优先放入本地队列，如果本地队列满了， 则会将队列中一半的 `G` 移动到全局队列中。

- **P 的数量**：`P` 的数量是固定的，由 `GOMAXPROCS` 决定，即最大并发数, 默认为 `CPU` 核数。
- **M 的数量**：`M` 的数量是动态的，由调度器决定，根据当前的负载情况动态调整, GO默认设置为 10000，实际上内核很难达到该限制，可以认为是没有限制。`M` 想要运行任务就需要获取 `P`，如果没有 `P`，`M` 就会阻塞。如果 `P` 的本地队列为空，`M` 会从全局队列中获取 `G`，放入本地队列。 如果全局队列也为空，`M` 会从其他随机一个 `P` 的本地队列中获取一半的 `G` 放到本地队列中。

<img src="./assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3htY3kwMDExMjI=,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述" style="zoom:67%;" />

- 调度器策略

  | 策略       | 描述                                                         |
  | ---------- | ------------------------------------------------------------ |
  | 抢占式调度 | 在协程中需要一个协程主动让出 CPU 下一个协程才能使用 CPU， 而 Goroutine 规定一个 Goroutine 每次**最多只能占用 10ms 的 CPU**，然后就要切换到下一个, 防止其他协程长时间不被执行 |
  | 复用线程   | 调度器会复用线程，而不是每次都创建新的线程，这样可以减少线程创建和销毁的开销，提高性能。 - **工作偷取(Work stealing)**:当 `M` 没有可运行的 `G` 时，会尝试从其他线程绑定的 `P` 的本地队列中偷取一半的 `G`来运行，而不是销毁 `M` - **挂起机制(Hand off)**: 当 `G` 由于系统调用而阻塞时, `M` 会释放绑定的 `P` 供其他 `M` 使用 |
  | 并行       | 通过 `GOMAXPROCS` 配置 `P` 的数量，从而实现并行执行，`P` 的数量决定了并行度，`P` 的数量等于 CPU 核数时，可以实现最大并行度。 |
  | 全局队列   | 当本地队列中没有可运行的 `G`， `M` 会先去全局队列尝试获取 `G`， 若全局队列中没有待运行的 `G` 则会尝试去其他 `P` 的本地队列中偷取 `G` |



## 8. 计网基础

### 8.1 TCP和IP模型

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-ad64bbac-e0d5-4286-9b77-d008e8c8d419.jpg" alt="各层网络对应的网络协议" style="zoom:50%;" />





### 8.2 HTTP

- **基于文本：** HTTP的消息是以文本形式传输，易于阅读和调试，但相比二进制协议效率较低。
- **可扩展性**：HTTP协议本身不限制数据的内容和格式，可以通过扩展头部、方法等来支持新的功能。
- **灵活性：** HTTP支持不同的数据格式（如HTML、JSON、XML等），适用于多种应用场景。
- **无状态：** **每个请求之间相互独立，服务器不会保留之前请求的状态信息**，需要通过其他手段（如Cookies、Session）来维护状态。



### 8.3 HTTP 版本/状态码

| 特性     | HTTP 1.0                                             | HTTP 1.1                                                     | HTTP 2.0                                                     |
| -------- | ---------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 连接方式 | 无连接，每次请求都要建立连接                         | **长连接**，减少了 TCP 连接的重复建立和断开所造成的额外开销  | **多路复用**，一个 TCP 连接上可以并发多个 HTTP 请求          |
| 队头阻塞 | 存在，下一个请求必须在前一个请求响应到达之前才能发送 | 存在，虽然可以发起多个请求，但服务器必须按照接收请求的顺序发送响应 | 解决，可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应 |

| 数字 | 含义                                                         |
| ---- | ------------------------------------------------------------ |
| 1XX  | 指示信息，表示请求以接收，继续处理                           |
| 2XX  | 成功，表示请求已经被成功接收、理解、接受                     |
| 3XX  | 状态码表示客户端请求的资源发送了变动，也就是**重定向**   301：永久重定向；302：临时重定向； |
| 4XX  | 状态码表示客户端发送的报文有误，服务器无法处理，也就是**错误码**的含义。 404：无法找到此页面；405：请求的方法类型不支持； |
| 5XX  | 状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于**服务器端的错误码**   500：服务器内部出错。 |



### 8.4 HTTPS

HTTP协议运⾏在TCP之上，所有传输的内容都是明⽂，客户端和服务器端都⽆法验证对⽅的⾝份。

HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程。所有传输的内容都经过加密，加密采⽤对称加密(DES AES)，但对称加密的密钥⽤服务器⽅的证书进⾏了⾮对称加密（RSA DSA）。



- TLS 协议（RSA算法）

1. 客户端向服务器**发起加密通信请求**，也就是 `ClientHello` 请求。

客户端主要向服务器发送以下信息：TLS 协议版本；生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一；加密算法；



2. **服务器响应**，也就是 `SeverHello`。服务器回应的内容有如下内容：

（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。

（2）服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）**服务器的数字证书**。



3. 客户端验证服务器

<img src="./assets/22-数字证书工作流程.jpeg" alt="数子证书工作流程" style="zoom: 67%;" />

客户端通过浏览器或者操作系统中的 **CA 公钥**，确认服务器的数字证书的真实性。如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密发送的随机数（`pre-master key`）。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。



4. 服务器解密并生成会话密钥

收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。



- **会话复用？**「复用」对称加密密钥，减少 TLS 握手的性能损耗。

Session Ticket。服务器会**加密「会话密钥」**作为 Ticket 发给客户端，交给客户端缓存该 Ticket。客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后**验证有效期**，如果没问题，就可以恢复会话了，开始加密通信。



### 8.5 有HTTP 为什么还需要rpc

**HTTP/REST**

- 更适合**对外开放的 API 接口**，尤其是面向多种客户端的应用（如浏览器、移动端）场景，因其基于标准的 HTTP 协议，具有良好的兼容性和广泛的支持。
- 适合资源导向的操作，如 CRUD 操作，特别是对资源的创建、读取、更新和删除。

**RPC**

- 适合**微服务内部通信**，尤其在高性能、低延迟要求的环境中（如大型分布式系统、服务网格）。
- 更适合**频繁的服务调用**或方法调用，比如需要多个微服务之间频繁的数据交互。

HTTP 的本质是客户端和服务端约定好的一种通信格式，**基于请求-响应模型。**HTTP 就规定了请求先搞请求行、再搞请求报头、再搞请求体。响应就状态行、响应报头、响应体。**写一大份接口文档**，严格地标明输入输出是什么。

RPC（Remote Procedure Call）是一种远程过程调用协议，用于实现分布式系统中不同节点之间的通信。它**基于方法调用模型**，允许客户端调用远程服务的方法，并等待结果返回。RPC 框架，屏蔽这些底层调用细节。 **HTTP 协议比较的冗余**，RPC 都是内部调用所以不需要太考虑通用性。RPC 可以采用体积更小的 **Protobuf** 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样**考虑各种浏览器行为**，比如 302 重定向跳转啥的。

很多RPC框架包含了**重试机制，路由策略，负载均衡策略，高可用策略，流量控制策略**等等。 如果应用进程之间只使用HTTP协议通信，显然是无法完成上述功能的。



### 8.6 打开https://www.baidu.com的过程

- **DNS 解析**：当用户输入一个网址并按下回车键的时候，浏览器获得一个域名，而在实际通信过程中，我们需要的是一个 IP 地址，因此我们需要先把域名转换成相应 IP 地址。

- **TCP 连接**：浏览器通过 DNS 获取到 Web 服务器真正的 IP 地址后，便向 Web 服务器发起 TCP 连接请求，通过 TCP 三次握手建立好连接。

  - 建立TCP协议时，需要发送数据，发送数据**在网络层使用IP协议， 通过IP协议将IP地址封装为IP数据报**；
  - 路由器与服务器通信会用到**ARP协议**，主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此**确定目标的物理地址，找到目的MAC地址**；

  - IP数据包在路由器之间，**路由选择使用OPSF(开放式最短路径优先)协议**， 采用Dijkstra算法来计算最短路径树，抵达服务端。

- **发送 HTTP 请求**：建立 TCP 连接之后，浏览器向 Web 服务器发起一个 HTTP 请求（如果是HTTPS协议，发送HTTP 请求之前还需要完成**TLS四次握手**）；

- **服务器处理请求**：服务器获取到客户端的 HTTP 请求后，会根据 HTTP 请求中的内容来决定如何获取相应的文件，并将文件发送给浏览器。

- **浏览器接收 HTTP 响应**：浏览器根据响应开始显示页面，首先解析 HTML 文件构建 DOM 树，然后解析 CSS 文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。



## 9. 操作系统基础

### 9.1 虚拟内存

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**程序所使用的内存地址叫做**虚拟内存地址**。



### 9.2 进程间的通信方式

1. 管道

```bash
$ ps auxf | grep mysql
```

「`|`」竖线就是一个**管道**，它的功能是将前一个命令（`ps auxf`）的输出，作为后一个命令（`grep mysql`）的输入，可以看出**管道传输数据是单向的**。

2. 消息队列

**消息队列是保存在内核中的消息链表**。**消息队列不适合比较大数据的传输**。**消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**

3. 共享内存（使用信号量 互斥写）

**共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**

4. 信号

信号是进程间通信机制中**唯一的异步通信机制**。

- Ctrl+C 产生 `SIGINT` 信号，表示终止该进程；
- Ctrl+Z 产生 `SIGTSTP` 信号，表示停止该进程，但还未结束；

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程；

5. socket

```go
	// 监听端口
	listener, err := net.Listen("tcp", ":8080")
	for {
		// 接受连接
		conn, err := listener.Accept()
		// 处理连接
		go handleRequest(conn)
	}
```



服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

<img src="./assets/12-TCP编程模型.jpg" alt="img" style="zoom: 50%;" />



### 9.3 零拷贝

传统的文件传输：期间共**发生了 4 次用户态与内核态的上下文切换**；还**发生了 4 次数据拷贝**

> 在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此**用户缓冲区是没有必要存在的**

<img src="./assets/传统文件传输.png" alt="img" style="zoom: 50%;" />

- mmap + write

减少一次数据拷贝的过程

<img src="./assets/mmap %2B write 零拷贝.png" alt="img" style="zoom:50%;" />

- sendfile

1. 通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
2. 缓冲区描述符和数据长度传到 socket 缓冲区，网卡的 SG-DMA 控制器就可以**直接将内核缓存中的数据拷贝到网卡的缓冲区**；

<img src="./assets/senfile-零拷贝.png" alt="img" style="zoom: 50%;" />



零拷贝（Zero-copy）技术，因为**没有在内存层面去拷贝数据**，所有的数据都是通过 DMA 来进行传输的。



### 9.4 I/O 多路复用

1. select/poll

select 和 poll 并没有本质区别，它们内部都是使用**「线性结构」**来存储进程关注的 Socket 集合。

在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态**拷贝**到内核态，然后由内核检测事件，当有网络事件产生时，内核需要**遍历**进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态**拷贝**到用户态，用户态还要继续**遍历**整个 Socket 集合找到可读/可写的 Socket，然后对其处理。

很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销。



2. epool

- epoll 在内核里使用**「红黑树」**来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，**增删改一般时间复杂度是 O(logn)**，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都**传入整个** Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。
- epoll 使用**事件驱动**的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。

<img src="./assets/epoll.png" alt="img" style="zoom:50%;" />



## 10. TCP 三次握手 四次挥手

### 10.1 三次握手

1. 客户端发送`SYN=1`，并指明客户端的初始序列号`ISN`，即`x`.
2. 服务端发送自己的`SYN`段作为应答，同样指明自己的`ISN` 即 `y`。为了确认客户端的`SYN`，将`x+1`作为`ACK`数值。这样，每发送一个`SYN`，序列号就会加1. 如果有丢失的情况，则会重传。
3. 为了确认服务器端的`SYN`，客户端将`y+1`作为返回的`ACK`数值。

> **TCP 建立连接的过程就是同步序列号的过程**，SYN (Synchronize Sequence Numbers)就是同步序列号。因此，三次握手的目的就是使客户端(Client)和服务端(Service)获取到对方的序列号。
>
> 三次握手的**首要原因是为了防止旧的重复连接初始化造成混乱。**

<img src="./assets/tcp-connect.png" alt="TCP Connection" style="zoom: 45%;" />

### 10.2 四次挥手

（1）客户端发送⼀个FIN
⽤来关闭客户端到服务器的数据传送，此后客户端进⼊FIN_WAIT_1状态。
（2）服务器收到FIN后
进⼊CLOSE_WAIT状态。正常情况下会发送⼀个ACK给客户端，确认序号为收到序号+1（与SYN相同，⼀个FIN占
⽤⼀个序号）。
（3）服务器发送⼀个FIN
⽤来关闭服务器到客户端的数据传送，服务器进⼊LAST_ACK状态。
（4）客户端收到FIN后
客户端进入TIME_WAIT状态，接着发送⼀个ACK给服务器，确认序号为收到序号+1，服务器进⼊CLOSED状态，
完成四次挥手。

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-ba156295-03af-46dc-8ef3-869b44b11303.jpg" alt="三分恶面渣逆袭：TCP 四次挥手" style="zoom: 40%;" />

> - 为什么需要四次挥手

**之所以需要四次挥手，是因为 tcp 是全双工协议，即客户端和服务端都可以主动发送消息，因此需要两端分别在传输完成后发送断开连接的指令，需要分别发送 `FIN=1` 指令断开，通过 `ACK` 判断是否发送成功。**

当被动关闭方（上图的服务端）在 TCP 挥手过程中，**「没有数据要发送」并且「开启了 TCP 延迟确认机制」**，那么第二和第三次挥手就会合并传输，这样就出现了**三次挥手**。

> - 为什么 TIME_WAIT 等待的时间是 2MSL（报文最大生存时间）

**2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

> - 为什么需要 TIME_WAIT

防止历史连接中的数据，被后面相同四元组的连接错误的接收：**让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

保证「被动关闭连接」的一方，能被正确的关闭；

> - 服务器出现大量 TIME_WAIT

- 第一个场景：HTTP 没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限

解决？如果服务端要避免过多的 TIME_WAIT 状态的连接，就**永远不要主动断开连接**，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。

> - 服务器出现大量 CLOSE_WAIT

CLOSE-WAIT 状态：此时服务端可能还有一些**数据没有传输完成**，因此不能立即关闭连接。当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，主要分析的方向就是服务端为什么**没有调用 close**。



### 10.3 保证可靠性

1. **校验和**：TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果接收端的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
2. **序列号/确认应答**：TCP 给发送的每一个包进行编号，接收方会对收到的包进行应答，发送方就会知道接收方是否收到对应的包，如果发现没有收到，就会重发，这样就能保证数据的完整性。
3. **流量控制：**TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。
4. **超时重传：**超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。
5. **拥塞控制：**TCP 引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据。



### 10.4 滑动窗口

接收窗口的大小是**约等于**发送窗口的大小的。传输过程是存在时延的。

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-4ce3171e-065c-46e3-9b22-626837cf774e.jpg" alt="发送端滑动窗口" style="zoom:50%;" />

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-ba692020-9702-4b8c-b007-8a6539f78f72.jpg" alt="接收方滑动窗口" style="zoom:50%;" />



### 10.5 超时重传

**超时重传**：超时重传时间 RTO 略微大于 RTT

**快速重传**机制下，在数据包丢失后，接收端每接收一个失序的数据包就立即返回重复的确认报文段，告知发送端缺少的报文段。当发送方**收到三个重复的确认报文段**后，会立即重传缺失的报文段。

**带选择确认的重传**：**SACK 机制**就是，在快速重传的基础上，接收方返回最近收到报文段的序列号范围。

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-947df4b4-2e14-482b-9b5d-37cb01a0b5c2.jpg" alt="SACK 机制" style="zoom: 67%;" />





### 10.6 拥塞控制

发送方维护一个**拥塞窗口 cwnd（congestion window）**  **慢启动阀值 ssthresh**。

1. 慢启动

<img src="./assets/weixin-mianznxjsjwllsewswztwxxssc-1cb5d1ed-373c-47c8-9b2d-33ff197bf331.jpg" alt="拥塞发生算法" style="zoom:50%;" />

2. [**快重传和快恢复**](https://goguide.ryansu.tech/guide/concepts/network/3-tcp-udp.html#快重传和快恢复)

快重传在前面已介绍过，即如果连续收到三个重复的确认就会立即发送尚未接收到的报文段。快恢复算法需要配合快重传算法使用。

快恢复算法：

- 当发送端连续收到三个重复的确认时，将 `ssthresh` 减半。
- 将 `cwnd` (拥塞窗口)设置为 `ssthresh` (慢开始门限)的大小



## 11. UDP

> 无连接、速度快、不可靠性、应用广泛

- 不保证消息交付：不确认，不重传，无超时
- 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞
- 不跟踪连接状态：不必建立连接或重启状态机
- 不进行拥塞控制：不内置客户端或网络反馈机制

| 特性/指标              | TCP（Transmission Control Protocol）                         | UDP（User Datagram Protocol）                                |
| ---------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **连接方式**           | 面向连接，需建立连接（三次握手）                             | 无连接，直接发送数据包                                       |
| **可靠性**             | 提供可靠的传输服务，确保数据包按顺序到达，不丢失、不重复     | 不可靠传输，不保证数据包的可靠性和顺序性                     |
| **流控制**             | 有流控制，通过滑动窗口机制控制发送速率                       | 无流控制，发送方可以快速发送数据                             |
| **拥塞控制**           | 有拥塞控制，通过算法调整发送速率，避免网络拥塞               | 无拥塞控制，不对网络状况进行调整                             |
| **传输开销**           | 较高，需建立和维护连接                                       | 低，无需建立和维护连接                                       |
| **传输延迟**           | 较高，由于可靠性和流控机制                                   | 低，由于没有可靠性和流控机制                                 |
| **适用场景**           | 文件传输（FTP、SFTP）、电子邮件（SMTP）、网页浏览（HTTP/HTTPS）、数据库连接（如 MySQL、PostgreSQL） | 实时应用（音视频流、VoIP、在线游戏）、广播和组播（实时更新、状态信息广播）、简单的查询响应协议（如 DNS） |
| **实例比较：视频会议** | 不太适合，重传机制会导致延迟增加，影响实时性                 | 适合，需要低延迟，即使偶尔丢失一些数据包也不影响太大         |
| **实例比较：文件传输** | 适合，需要确保数据的完整性和顺序性，避免文件损坏             | 不适合，不保证数据的可靠性和顺序性，容易导致文件损坏         |



## 12. MySQL

### 12.1 B+树

MySQL数据库**索引**采⽤的是B+Tree结构，在B-Tree结构上做了优化改造。

- B-Tree结构

1. 索引值和data数据**分布在整棵树**结构中

2. 每个节点可以存放多个索引值及对应的data数据

3. 树节点中的多个索引值从左到右升序排列


- B+Tree结构：

1. ⾮叶⼦节点不存储data数据，只存储索引值，这样便于存储更多的索引值
2. **叶⼦节点包含了所有的索引值和data数据**
3. 叶⼦节点⽤**指针连接**，提⾼区间的访问性能

B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O，所以**B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。**

**B+ 树的插入和删除效率更高**。

B+Tree 叶子节点采用的是**双向链表连接**，适合 MySQL 中常见的**基于范围的顺序查找**。



### 12.2 聚簇索引

聚簇索引就是按照每张表的**主键构造一颗B+树**，同时叶子节点中存放的就是整张表的**行记录数据**，也将聚簇索引的叶子节点称为数据页。
聚簇索引的数据的**物理存放顺序与索引顺序是一致的**，如果不用自增id作为主键，需要不断调整数据的物理地址。   

- 聚簇索引和非聚簇索引的区别

| 特性                 | 聚簇索引（Clustered Index）                | 非聚簇索引（Non-Clustered Index）          |
| -------------------- | ------------------------------------------ | ------------------------------------------ |
| **数据存储方式**     | 数据行按索引键顺序存储                     | 存储索引键和指向数据行的指针               |
| **索引数量**         | 每个表只能有一个                           | 每个表可以有多个                           |
| **存储空间**         | 占用更多存储空间                           | 占用较少存储空间                           |
| **查询性能**         | 范围查询性能更高                           | 查询性能较高，但需要一次额外的跳转         |
| **插入、更新、删除** | 插入、更新和删除操作可能导致数据行重新排列 | 插入、更新和删除操作不影响数据行的物理顺序 |
| **主键**             | 通常默认作为聚簇索引                       | 可以为任意列创建非聚簇索引                 |
| **范围查询**         | 范围查询非常高效                           | 范围查询效率较低                           |

从物理存储的角度来看，索引分为**聚簇索引（主键索引）**、二级索引（辅助索引）。

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

>  回表的优化？

1. 索引覆盖（数据小，大概率在内存，速度快）

如果查询的数据能在二级索引里查询的到（刚好要查询主键），那么就不需要**回表**，这个过程就是**覆盖索引**。否则需要先读取主键然后检索主键索引，这个过程就是**回表**。

覆盖索引：索引本身**包含了需要查询的所有字段**。

MySQL **只能使用B+Tree**索引做覆盖索引，因为只有B+树能存储索引列值。

2. 索引下推

索引下推优化的**核心思想**是将WHERE子句中的部分条件直接下推到索引扫描的过程中。**只有符合条件再进行回表**，对索引中包含的字段先进行判断，不符合条件的跳过。减少了不必要的回表操作。



### 12.3 索引失效

 6 种会发生索引失效的情况：

- 使用**左或者左右模糊匹配**的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 在查询条件中**对索引列使用函数**，就会导致索引失效。
- 在查询条件中**对索引列进行表达式计算**，也是无法走索引的。
- MySQL 在遇到字符串和数字比较的时候，会**自动把字符串转为数字**，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 联合索引要能正确使用需要遵循**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 **OR** 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



### 12.4 InnoDB存储数据

<img src="./assets/261011d237bec993821aa198b97ae8ce.png" alt="图片" style="zoom: 40%;" />

**数据页中的记录按照「主键」顺序组成单向链表**，数据页中有一个**页目录**，起到记录的索引作用。

**页目录就是由多个槽组成的，槽相当于分组记录的索引**。然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表。

> - 第一个分组中的记录只能有 1 条记录；
> - 最后一个分组中的记录条数范围只能在 1-8 条之间；
> - 剩下的分组中记录条数范围只能在 4-8 条之间。



> MySQL 的 NULL 值是怎么存放的？

MySQL 的 Compact 行格式中会用**「NULL值列表」**来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表。

> MySQL 怎么知道 varchar(n) 实际占用数据的大小？

MySQL 的 Compact 行格式中会用**「变长字段长度列表」**存储变长字段实际占用的数据大小。

<img src="./assets/COMPACT.drawio.png" alt="img" style="zoom: 33%;" />

> varchar(n) 中 n 最大取值为多少？

一行记录最大能存储 65535 字节的数据。但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。

> 行溢出后，MySQL 是怎么处理的？

如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到**「溢出页」**中。

Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。

<img src="./assets/行溢出.png" alt="img" style="zoom: 33%;" />

Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中



### 12.5 锁

1. 行级锁的类型主要有三类：

- Record Lock，记录锁，也就是仅仅把一条记录锁上；

  当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（**S 型与 S 锁兼容**），但是不可以对该记录加 X 型记录锁（**S 型与 X 锁不兼容**）;

- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；

  **间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁**。间隙锁的意义只在于阻止区间被插入，因此是可以共存的。**一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁**。

- Next-Key Lock：**临键锁**，Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。

- 插入意向锁：

  一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态。




2. update 没加索引会锁全表？

关键还得看这条语句在执行过程，**优化器最终选择的是索引扫描，还是全表扫描**



### 12.6 避免死锁

- **设置事务等待锁的超时时间**。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了。在 InnoDB 中默认50s
- **开启主动死锁检测**。
- 业务角度：对订单做**幂等性校验**的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一性来保证订单表不会出现重复的订单，不过有一点不好的地方就是**在插入一个已经存在的订单记录时抛出异常**。



### 12.7 Buffer Pool

Innodb 存储引擎设计了一个**缓冲池（Buffer Pool）**，来提高数据库的读写性能。

Buffer Pool 以页为单位缓冲数据，可以通过 `innodb_buffer_pool_size` 参数调整缓冲池的大小，默认是 128 M。

Innodb 通过三种链表来管理缓页：

- Free List （空闲页链表），管理空闲页；
- Flush List （脏页链表），管理脏页；
- LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。；

InnoDB 对 LRU 做了一些优化：

- 将 LRU 链表 分为**young 和 old 两个区域**，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决**预读失效**的问题。
- 当**「页被访问」且「 old 区域停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒）」**时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，**大量热数据淘汰**的问题。



### 12.8 [不要使用_SELECT *](https://www.cnblogs.com/MrYuChen-Blog/p/13936680.html)

1. 使用 * 号查询，会查询出不需要的字段，增加sql执行的时间，同时大量的多余字段，会增加网络开销
2. 对于无用的大字段，如 varchar、blob、text，会增加 io 操作
3. SELECT * 杜绝了覆盖索引的可能性，而基于MySQL优化器的“覆盖索引”策略又是速度极快，效率极高，业界极为推荐的查询优化方式（本身通过覆盖索引不需要回表，结果SELECT * 强行回表）



### 12.9 联合索引-最左匹配

由多个字段组成的索引就是联合索引。数据库在使用联合索引时，会从最左边的列开始匹配，直到遇到第一个范围查询或无法匹配的列为止。具体来说：

1. 索引 `(A, B, C)` 可以加速以下类型的查询：
   - 匹配列 `A`
   - 匹配列 `A` 和列 `B`
   - 匹配列 `A`、列 `B` 和列 `C`
2. 索引 `(A, B, C)` 不能有效加速以下类型的查询：
   - 仅匹配列 `B` 或列 `C`
   - 仅匹配列 `B` 和列 `C`



- 下面这条SQL，该怎么创建**联合索引**？

```sql
SELECT * FROM test WHERE a = 1 and b = 1 and c = 1;
```

你以为的答案是（`a`,`b`,`c`），其实答案是6个，abc三个的排列组合，（`a`,`b`,`c`）、（`a`,`c`,`b`）、（`b`,`a`,`c`）、（`b`,`c`,`a`）、（`c`,`a`,`b`）、（`c`,`b`,`a`）。**MySQL优化器为了适应索引，会调整条件的顺序。**

**区分度高的字段放在最前面**。如何统计每个字段的区分度？

```sql
select 
    count(distinct a)/count(*), 
    count(distinct b)/count(*),
    count(distinct c)/count(*)
from test;
```

---

- 下面这条SQL，该怎么创建**联合索引**？

```sql
SELECT * FROM test WHERE a = 1 and b > 1 and c = 1;
```

**联合索引遇到范围匹配会停止**，不会再匹配后面的索引字段。（`a`,`c`,`b`）和 （`c`,`a`,`b`）。

---

- 下面这条SQL，该怎么创建**联合索引**？

```sql
SELECT * FROM test WHERE a in (1,2,3) and b > 1;
```

答案是（`a`,`b`）。**in条件查询会被转换成等值查询。**

在平时做开发，尽量想办法**把范围查询转换成in条件查询**，效率更高。



### 12.10 MySQL执行流程

<img src="./assets/mysql查询流程.png" alt="查询语句执行流程" style="zoom: 50%;" />

1. 连接器

   - 与客户端进行 TCP 三次握手建立连接；
   - 校验客户端的用户名和密码；
   - 读取该用户的权限，后面的权限逻辑判断都基于此时读取到的权限（即使中途权限发生修改）；

2. 查询缓存

   - 只要一个表有更新操作，那么这个表的查询缓存就会被清空；
   - MySQL 8.0 版本直接将查询缓存删掉了；

3. 解析 SQL

   - **词法分析**，识别关键字和非关键字
   - **语法分析**，构建语法树

4. 执行 SQL

   - **预处理阶段**；检查 SQL 查询语句中的表或者字段是否存在，将 `*` 符号扩展为表上的所有列；

   - **优化器；**将 SQL 查询语句的执行方案确定下来

     > ```sql
     > select id from product where id > 1  and name like 'i%';
     > ```
     >
     > 执行过程中使用普通索引（name），Exta 为 Using index，这就是表明使用了覆盖索引优化。

   - **执行器；**



### 12.11 慢SQL

定位慢 SQL 主要通过两种手段：

- **慢查询日志**：开启 MySQL 慢查询日志，再通过一些工具比如 mysqldumpslow 去分析对应的慢查询日志，找出问题的根源。
- **服务监控**：可以在业务的基建中加入对慢 SQL 的监控，常见的方案有字节码插桩、连接池扩展、ORM 框架过程，对服务运行中的慢 SQL 进行监控和告警。

explain 是 MySQL 提供的一个用于查看查询执行计划的工具：

- **type** 列：表示 MySQL 在表中找到所需行的方式，性能从最优到最差分别为：system > const > eq_ref > ref > range > index > ALL。
- **key** 列：实际使用的索引。如果为 NULL，则没有使用索引。
- **rows** 列：估算查到结果集需要扫描的数据行数，原则上 rows 越少越好。
- **Extra** 列：附加信息。Using index：表示只利用了索引。Using where：表示使用了 WHERE 过滤。

<img src="./assets/mysql-20240417092646.png" alt="二哥的 Java 进阶之路" style="zoom:33%;" />



## 13. SQL事务

### 13.0 一条update语句的执行过程

具体更新一条记录 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 的流程如下:

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
   - 如果 id=1 这一行所在的数据页本来就在 **buffer pool** 中，就直接返回给执行器更新；
   - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
   - 如果一样的话就不进行后续更新流程；
   - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要**生成一条 undo log**，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。
4. InnoDB 层开始更新记录，会先**更新内存**（同时标记为脏页），然后将记录**写到 redo log** 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 **WAL 技术**，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 **binlog**，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在**事务提交时**才会统一将该事务运行过程中的所有 binlog **刷新到硬盘**。
7. 事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：
   - **prepare 阶段**：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
   - **commit 阶段**：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；
8. 至此，一条更新语句执行完成。



### 13.1 MySQL 保证一致性 三大日志

> 数据库通过原子性、隔离性、持久性来保证⼀致性。

- Mysql 怎么保证原子性的？（**undo log**）


利⽤Innodb的 **undo log** 。undo log 名为**回滚日志**，是实现原⼦性的关键，当事务回滚时能够**撤销所有已经成功执⾏的sql语句**，他需要记录你要回滚的相应⽇志信息。

> delete ⼀条数据：记录这条数据的信息，回滚的时候，insert 这条旧数据;
> update ⼀条数据：记录之前的旧值，回滚的时候，根据旧值执⾏ update 操作;
> insert ⼀条数据：这条记录的主键，回滚的时候，根据主键执⾏ delete 操作.

undo log 记录了这些回滚需要的信息，当事务执⾏失败或调⽤了 rollback，导致事务需要回滚，便可以利⽤undo
log 中的信息将数据回滚到修改之前的样⼦。

undo log 还有一个作用，**通过 ReadView + undo log 实现 MVCC（多版本并发控制）**。



- Mysql 怎么保证持久性的？(**redo log)**

利⽤ Innodb 的 redo log **重做日志**。Mysql是先把磁盘上的数据加载到内存中，在内存中对数据进⾏修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。**redo log 是循环写**，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。**redo log满了MySQL会被阻塞。**

**WAL（Write-Ahead Logging）技术**：MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。**在事务提交时，只要先将 redo log 持久化到磁盘即可**，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。redo log 是物理日志，记录了某个数据页做了什么修改，比如**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**。

<img src="./assets/wal.png" alt="img" style="zoom: 50%;" />

- 为什么需要 redo log ？

  1. **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；

  2. **将写操作从「随机写」变成了「顺序写」**，提升 MySQL 写入磁盘的性能。因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。

- 什么时候刷盘？

  - MySQL 正常关闭时；
  - 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时；
  - InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
  - 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘。



- MySQL 主从复制原理 **binlog** 


Binary log（二进制日志）记录了数据库所有执行的DDL和DML等数据库**更新事件**的语句，但是不包含没有修改任何数据的语句（如数据查询语句select、show等）。它以`事件形式`记录并保存在`二进制文件`中。

- 一是用于`数据恢复`，如果MySQL数据库意外停止，可以通过二进制日志文件来查看用户执行了哪些操作，对数据库服务器文件做了哪些修改，然后根据二进制日志文件中的记录来恢复数据库服务器。

- 二是用于`数据复制`，由于日志的延续性和时效性，master把它的二进制日志传递给slaves来达到master-slave数据一致的目的。分三个阶段：**写入、同步、回放**

  <img src="./assets/主从复制过程.drawio.png" alt="MySQL 主从复制过程" style="zoom:80%;" />



- MySQL 磁盘 I/O 很高？

1. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync

2. 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件



### 13.2 两阶段提交

MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决。**两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」**。

> **将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog**

<img src="./assets/两阶段提交.drawio.png" alt="两阶段提交" style="zoom: 40%;" />



### 13.3 隔离级别（隔离性）

| 术语         | 定义                                                         |
| ------------ | ------------------------------------------------------------ |
| **读未提交** | 存在**脏读**：指的是读到了**其他事务未提交的数据**，未提交意味着这些数据可能会回滚，也就是不存在的数据。 |
| **读已提交** | 存在**不可重复读**：对比可重复读，不可重复读指的是**在同一事务内，不同的时刻读到的同一批数据可能是不一样的**，可能会受到其他事务的影响，比如其他事务改了这批数据并**提交了**。不可重复读常在数据更新时出现。 |
| **可重复读** | 存在**幻读**：在一个事务中明明没有查到主键为 X 的数据，但主键为 X 的数据就是插入不进去；多次读取一个范围内的记录, 发现结果不一致 |

> MySQL 的默认隔离级别是 `REPEATABLE-READ`（可重复读），在一个事务中多次读取同一行数据时，总会读取到相同的数据。这是通过在事务开始时生成数据的**快照**来实现的。
>
> 「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后**整个事务期间都在用这个 Read View**。

在 MySQL 中，主要通过 **MVCC**（多版本并发控制）来实现隔离性，MVCC 是通过保存数据在某个时间点的快照来实现的，这样可以保证事务在执行过程中看到的数据是一致的。

<img src="./assets/f595d13450878acd04affa82731f76c5.png" alt="图片" style="zoom:50%;" />

- trx_id，事务id
- roll_pointer，指向每一个旧版本记录

<img src="./assets/ReadView.drawio.png" alt="img" style="zoom:50%;" />

- 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

---



### 13.4 解决幻读？

MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象，解决的方案有两种：

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时**看到的数据是一致的**，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。





## 14. Redis

> Redis (Remote Dictionary Service) 是一种**基于内存**的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。

### 14.1 为什么用 Redis 作为 MySQL 的缓存？

主要是因为 **Redis 具备「高性能」和「高并发」两种特性**。
高性能：直接操作内存；高并发：单机QPS是mysql的十倍（10w+）

之所以 Redis 采用**单线程**（网络 I/O 和执行命令）那么快，有如下几个原因：

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；

- Redis 采用**单线程模型**可以避免了多线程之间的竞争，省去了**多线程切换**带来的时间和性能上的开销，而且也不会导致死锁问题。

  > Redis 为「**关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程**来处理

- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指**一个线程处理多个 IO 流**，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。**内核会一直监听这些 Socket 上的连接请求或数据请求**。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。



### 14.2 五种常见的 Redis 数据类型

<img src="./assets/9fa26a74965efbf0f56b707a03bb9b7f.png" alt="img" style="zoom:50%;" />

1. **String** 类型内部实现

String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串：

- **SDS 不仅可以保存文本数据，还可以保存二进制数据**。因为 SDS 使用 **len 属性**的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。
- **SDS 获取字符串长度的时间复杂度是 O(1)**。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。
- **Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出**。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。

![img](./assets/raw.png)

`embstr`会通过一次内存分配函数来分配**一块连续的内存空间**来保存`redisObject`和`SDS`
`raw`编码会通过调用两次内存分配函数来分别分配**两块空间**来保存`redisObject`和`SDS`

**embstr编码的字符串对象实际上是只读的**，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。



2. **List** 类型内部实现

List 类型的底层数据结构是由**quicklist **实现的：

<img src="./assets/消息队列.png" alt="img" style="zoom: 33%;" />

基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。

- 消息保序：使用 LPUSH + RPOP；
- 阻塞读取：使用 BRPOP；
- 重复消息处理：生产者自行实现全局唯一 ID；
- 消息的可靠性：使用 BRPOPLPUSH；**Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存**。



3. **Hash** 类型内部实现

Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

- 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；
- 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的底层数据结构。

<img src="./assets/hash.png" alt="img" style="zoom: 33%;" />

**购物车**：以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素



4. **Set** 类型内部实现

Set 类型的底层数据结构是由**哈希表或整数集合**实现的；

**Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞**。

**点赞**：Set 类型可以保证一个用户只能点一个赞，key 是文章id，value 是用户id。

获取 article:1 文章所有点赞用户 :

```shell
> SMEMBERS article:1
1) "uid:3"
2) "uid:2"
```

获取 article:1 文章的点赞用户数量：

```shell
> SCARD article:1
(integer) 2
```



**共同关注**：Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。

给 `uid:2` 推荐 `uid:1` 关注的公众号：

```shell
> SDIFF uid:1 uid:2
1) "5"
2) "6"
```



5. **ZSet** 类型内部实现

Zset 类型的底层数据结构是由**跳表**实现的：

![image-20230813003238511](./assets/a878b18a7c402b2f621558c65d235d66.png)

在 Redis 可以使用**有序集合（ZSet）**的方式来实现**延迟消息队列**的，ZSet 有一个 **Score 属性可以用来存储延迟执行的时间**。使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 **zrangebysocre** 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。

<img src="./assets/延迟队列.png" alt="img"  /> 



- Mysql 为什么使用 B+树，而不是跳表？

Mysql 数据库是持久化数据库，即是存储到磁盘上的，因此**查询时要求更少磁盘 IO**，且 Mysql 是读多写少的场景较多，显然 B+ 树更加适合Mysql。

- Redis 的 ZSet 为什么使用跳表而不是B+树

Redis 是内存存储，**不存在 IO 的瓶颈**，所以跳表的层数的耗时可以忽略不计，而且插入数据时不需要开销以平衡数据结构（**写多**）。

---



### 14.3 如何避免缓存雪崩、缓存击穿、缓存穿透？

> 如何避免缓存雪崩？

<img src="./assets/e2b8d2eb5536aa71664772457792ec40.png" alt="img" style="zoom:50%;" />

**当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求**，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。

对于缓存雪崩问题：

- **将缓存失效时间随机打散：** 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）**分散缓存过期时间**，也就降低了缓存集体失效的概率。
- **集群部署：** Redis Cluster
- **限流和降级：**设置合理的系统限流策略，如令牌桶或漏斗算法；关闭一些非核心服务

> 如何避免缓存击穿？

如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是**缓存击穿**的问题。

<img src="./assets/acb5f4e7ef24a524a53c39eb016f63d4.png" alt="img" style="zoom: 50%;" />

可以发现缓存击穿跟缓存雪崩很相似，可以认为缓存击穿是缓存雪崩的一个子集。 应对缓存击穿可以采取前面说到两种方案：

- **互斥锁方案**（Redis 中使用 **setNX** 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个**业务线程请求缓存**，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
- **不给热点数据设置过期时间**，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

> 如何避免缓存穿透？

**用户访问的数据，既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

<img src="./assets/b7031182f770a7a5b3c82eaf749f53b0.png" alt="img" style="zoom:50%;" />

缓存穿透的发生一般有这两种情况：

- **业务误操作**，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

应对缓存穿透的方案，常见的方案有三种。

- **非法请求的限制**：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。
- **设置空值或者默认值**：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样**后续请求就可以从缓存中读取到空值或者默认值**，返回给应用，而不会继续查询数据库。
- **使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在**：当检查一个元素是否存在于过滤器中时，同样使用 k 个哈希函数计算位置，如果任一位置的位为 0，则该元素**肯定不在**过滤器中；如果所有位置的位都为 1，则该元素**可能在**过滤器中。
  ![三分恶面渣逆袭：布隆过滤器](./assets/redis-d0b8d85c-85dc-4843-b4be-d5d48338a44e.png)



### 14.4 缓存更新策略

常见的缓存更新策略共有3种：

- Cache Aside（旁路缓存）策略；
- Read/Write Through（读穿 / 写穿）策略；
- Write Back（写回）策略；

实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。

> Cache Aside（旁路缓存）策略

**Cache Aside（旁路缓存）**策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。

<img src="./assets/6e3db3ba2f829ddc14237f5c7c00e7ce-20230309232338149.png" alt="img" style="zoom:50%;" />

**写策略的步骤：**

- **先更新数据库中的数据，再删除缓存中的数据。**

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据；
- **如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存**，并且返回给用户。

注意，写策略的步骤的顺序不能倒过来，即**不能先删除缓存再更新数据库**，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。

<img src="./assets/cc208c2931b4e889d1a58cb655537767-20230309232342573.png" alt="img" style="zoom:50%;" />

**为什么「先更新数据库再删除缓存」不会有数据不一致的问题？**

先更新数据库，再删除缓存也是会出现数据不一致性的问题，**但是在实际中，这个问题出现的概率并不高**。

**因为缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

<img src="./assets/1cc7401143e79383ead96582ac11b615-20230309232407419.png" alt="img" style="zoom:50%;" />

**Cache Aside 策略适合读多写少的场景，不适合写多的场景**，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：

- 一种做法是**在更新数据时也更新缓存**，只是在**更新缓存前先加一个分布式锁**，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；
- 另一种做法同样也是在更新数据时更新缓存，只是**给缓存加一个较短的过期时间**，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。



### 14.5 高可用集群

1. **主从复制**

所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。

<img src="./assets/2b7231b6aabb9a9a2e2390ab3a280b2d.png" alt="img" style="zoom:50%;" />

主从服务器之间的命令复制是**异步**进行的，无法实现强一致性保证。

2. **哨兵模式**

哨兵模式可以监控主从服务器，并且提供**主从节点故障转移的功能。**

<img src="./assets/26f88373d8454682b9e0c1d4fd1611b4.png" alt="img" style="zoom:33%;" />



3. **切片集群模式**

**Redis 切片集群**（Redis Cluster ）方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

<img src="./assets/redis-15341792-e7a6-428c-a109-22827e02be5f.png" alt="分配槽" style="zoom:50%;" />



### 14.6 Redis 管道、redis不保证原子性

<img src="./assets/管道模式.jpg" alt="img" style="zoom:50%;" />

使用**管道技术可以解决多个命令执行时的网络等待**，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。

**Redis 中并没有提供回滚机制**，虽然 Redis 提供了 **DISCARD** 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

> 事务执行过程中，如果命令入队时没报错，而事务提交后，实际执行时报错了，**正确的命令依然可以正常执行**，所以这可以看出 **Redis 并不一定保证原子性**



### 14.7 redis 分布式锁

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

- 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 **SET 命令带上 NX 选项来实现加锁**；
- 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 **EX/PX 选项，设置其过期时间**；
- 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，**每个客户端设置的值是一个唯一值，用于标识客户端**；

满足这三个条件的分布式命令如下：

```c
SET lock_key unique_value NX PX 10000 
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而**解锁的过程就是将 lock_key 键删除（del lock_key）**，但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要**先判断锁的 unique_value 是否为加锁客户端**，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 **Lua 脚本**来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

> 不支持可重入锁：
> 在分布式系统中，有时候同一个客户端可能需要多次获取同一个锁。使用 SETNX 实现的锁**不支持可重入性**，即一个客户端在持有锁的情况下再次请求锁时会被拒绝，这在实际应用中可能导致问题。



> Redis 如何解决集群情况下分布式锁的可靠性？

为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。

它是基于**多个 Redis 节点**的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。

Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。



### 14.8 大key

- `redis-cli --bigkeys`  返回每个数据类型中 Top1 的大 Key

- 使用 RdbTools 第三方开源工具，可以用来**解析 Redis 快照（RDB）文件**，找到其中的大 key。

比如，下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。

```shell
rdb dump.rdb -c memory --bytes 10240 -f redis.csv
```

处理大key？

1. 从 Redis 4.0 版本开始，可以采用**异步删除**法，**用 unlink 命令代替 del 来删除**。

2. **压缩和拆分 key**



### 14.9 AOF持久化（丢失数据少）

<img src="./assets/6f0ab40396b7fc2c15e6f4487d3a0ad7.png" alt="img" style="zoom: 50%;" />

1. 写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是**可能会给「下一个」命令带来阻塞风险**。

2. 写回策略（控制何时执行` fsync()` ）
   - **Always**，每次写操作命令执行完后，**同步**将 AOF 日志数据写回硬盘；
   - **Everysec**，先将命令写入到 AOF 文件的内核缓冲区，然后**每隔一秒**将缓冲区里的内容写回到硬盘；
   - **No**，先将命令写入到 AOF 文件的内核缓冲区，再**由操作系统决定**何时将缓冲区内容写回硬盘。

3. 重写机制

   重写过程不会解析原始的 AOF 文件，而是将当前内存中的数据库状态转换为一系列写命令，然后保存到一个新的 AOF 文件中。
   重写过程中，新的写命令会继续追加到旧的 AOF 文件中，同时也会被记录到一个缓冲区中。

   <img src="./assets/723d6c580c05400b3841bc69566dd61b.png" alt="img" style="zoom: 50%;" />



### 14.10 RDB快照（恢复数据快）

RDB 快照是**全量快照**的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。

执行 **bgsave（background）** 命令的时候，会通过 **`fork()`** 创建子进程，子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表**指向的物理内存还是一个**。（加快创建子进程的速度，毕竟创建子进程的过程中，是会**阻塞主线程**的。）

只有在发生修改内存数据的情况时，物理内存才会被复制一份。（**写时复制**）

<img src="./assets/ebd620db8a1af66fbeb8f4d4ef6adc68.png" alt="图片" style="zoom: 50%;" />

- `save <seconds> <changes> ` `save 60 10000`
  如果至少有 10000 个键被修改，60 秒后自动触发一次 RDB 持久化。
- Redis 服务器通过 SHUTDOWN 命令正常关闭，会自动执行一次 RDB 持久化。
- 主从复制：主节点会在后台自动触发 RDB 持久化，然后将生成的 RDB 文件发送给从节点。



- **混合持久化**

  在 AOF 重写日志时，`fork` 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里（数据更少丢失）。

  <img src="./assets/f67379b60d151262753fec3b817b8617.jpeg" alt="图片" style="zoom:50%;" />
  
  当需要恢复数据时，Redis **先加载 RDB 文件**来恢复到快照时刻的状态，然后**应用 RDB 之后记录的 AOF 命令**来恢复之后的数据更改，既快又可靠。



### 14.11 过期删除策略

Redis 使用的过期删除策略是「**惰性删除+定期删除**」这两种策略配和使用。

1. 惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，首先检查该 key 是否存在于过期字典中，检测 key 是否过期，如果过期则删除该 key。（**「过期字典」保存了数据库中所有 key 的过期时间**）
2. 定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查**
   - 从过期字典中随机抽取 20 个 key；
   - 检查这 20 个 key 是否过期，并删除已过期的 key；
   - 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」**大于 25%**，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

## 

